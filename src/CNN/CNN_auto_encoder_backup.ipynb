{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdi220/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mdi220/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/mdi220/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pathlib, sys, os, random, time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local systems, if running on collaboratory please change above\n",
      "['Note.txt', 'test copy.ipynb', 'CNN_training.ipynb', 'CNN_auto_encoder.ipynb', 'delete-files.py', 'Resnet_training.ipynb', 'CNN_training_test.ipynb']\n"
     ]
    }
   ],
   "source": [
    "# mounting google drive\n",
    "collaboratory = False\n",
    "\n",
    "if collaboratory:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/gdrive')\n",
    "    # !ln -s \"/gdrive/Shareddrives/HSC_project/HSC_ML\" \"/content/HSC_ML\"\n",
    "    os.chdir(\"/gdrive/Shareddrives/HSC_project/HSC_ML\")\n",
    "else: \n",
    "    print('Running on local systems, if running on collaboratory please change above')\n",
    "\n",
    "print(os.listdir())\n",
    "# print(os.getcwd())\n",
    "#!unzip ./HSC_ML/Output/TBCells_crops.zip -d ./HSC_ML/Output/\n",
    "\n",
    "if collaboratory:\n",
    "  image_folder = \"./Output/\"\n",
    "else:\n",
    "  image_folder = \"../../Output/TBCells_crops/Train_data/\"\n",
    "trained_weights = image_folder[:-11]+\"Results/Latest_Weight_CNN/\"\n",
    "\n",
    "\n",
    "if not os.path.exists(trained_weights):\n",
    "        os.makedirs(trained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic deformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pip install git+https://github.com/gvtulder/elasticdeform\n",
    "\n",
    "import numpy, imageio, elasticdeform\n",
    "from matplotlib import image\n",
    "\n",
    "augmented_data_req = False\n",
    "\n",
    "if augmented_data_req:\n",
    "    augmented_images = os.path.abspath(os.path.join(image_folder, os.pardir)) + \"/augmented_images/\"\n",
    "\n",
    "    if not os.path.exists(augmented_images):\n",
    "            os.makedirs(augmented_images)\n",
    "            \n",
    "\n",
    "    for folder in os.listdir(image_folder):\n",
    "        current_folder = os.path.join(image_folder, folder)\n",
    "        augmented_folder = augmented_images + folder + \"/\"\n",
    "        \n",
    "        if not os.path.exists(augmented_folder):\n",
    "            os.makedirs(augmented_folder)\n",
    "        for image_name in os.listdir(current_folder):\n",
    "            current_image = os.path.join(current_folder,  image_name)\n",
    "            # apply deformation with a random 3 x 3 grid\n",
    "            my_image = np.array(image.imread(current_image))\n",
    "            images_deformed = elasticdeform.deform_random_grid(my_image, sigma=3, points=2)\n",
    "            imageio.imsave( augmented_folder + image_name.split(\".\")[0] + \"_aug.tif\", images_deformed)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy generated images\n",
    "\n",
    "copy_augmented_data = False\n",
    "if copy_augmented_data:\n",
    "    import shutil\n",
    "    for folder in os.listdir(image_folder):\n",
    "        current_folder = os.path.join(image_folder, folder)\n",
    "        augmented_folder = augmented_images + folder + \"/\"\n",
    "        for image_name in os.listdir(augmented_folder):\n",
    "            current_image = os.path.join(augmented_folder,  image_name)\n",
    "            shutil.copy(current_image, current_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spliting dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ColorJitter(brightness = 0.25, contrast=0.25),\n",
    "    #transforms.RandomRotation(90),\n",
    "    transforms.RandomRotation(degrees=(90, 90)),\n",
    "    transforms.RandomRotation(degrees=(270, 270)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([transforms.Resize((64, 64)),transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "\n",
    "# add path of images https://gist.github.com/andrewjong/6b02ff237533b3b2c554701fb53d5c4d\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method that dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "\n",
    "\n",
    "dataset = ImageFolderWithPaths(image_folder, transform=train_transform)\n",
    "print(dataset.class_to_idx)\n",
    "train_indices, val_indices = sklearn.model_selection.train_test_split(\n",
    "                    list(range(dataset.__len__())),          # list of indices of dataset\n",
    "                    stratify = dataset.targets,                 # for stratify sampling the data due to the unblanced dataset\n",
    "                    random_state = 42,\n",
    "                    test_size=.25                               #represent the proportion of the dataset to include in the train split.\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "# subsetting the dataset into train and test\n",
    "training_data = torch.utils.data.Subset(dataset, train_indices)\n",
    "test_data = torch.utils.data.Subset(dataset, val_indices) \n",
    "\n",
    "print(f\"Length of dataset:\" )\n",
    "print(f\" {'Train dataset':<12}   \\u2502   {'Test data':>12} \")\n",
    "print(f\" {len(training_data):<12}    \\u2502   {len(test_data) :>12}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating and Visualizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"B Cells\",\n",
    "    1: \"T Cells\",\n",
    "    #2: \"T8 Cells\",\n",
    "\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label, _ = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.permute(1,2,0), cmap=\"gray\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 32\n",
    "\n",
    "# setting sampler weight\n",
    "y_train_indices = training_data.indices\n",
    "y_train = [dataset.targets[i] for i in y_train_indices]\n",
    "class_sample_count = np.array(\n",
    "    [len(np.where(y_train == t)[0]) for t in np.unique(y_train)])\n",
    "\n",
    "weight = 1. / class_sample_count\n",
    "samples_weight = np.array([weight[t] for t in y_train])\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, len(samples_weight), replacement=True) \n",
    "\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size= batch_size,sampler = sampler, pin_memory=True, )\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "for X, y, _ in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, in_features=3, classes=2):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_features, 16, kernel_size=3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Flatten(1),\n",
    "            nn.Linear(64, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN_AE(nn.Module):\n",
    "    def __init__(self, in_features=3, classes=50):\n",
    "        super().__init__()\n",
    "        self.encoder_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_features, 16, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "\n",
    "        self.encoder_pool1 = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "            \n",
    "        self.encoder_2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "        self.encoder_pool2 = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "        \n",
    "        self.encoder_3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64)\n",
    "            \n",
    "        )  \n",
    "\n",
    "        self.encoder_pool3 = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "        # #nn.AdaptiveAvgPool2d((1, 1)),\n",
    "\n",
    "        self.encoder_lin = nn.Sequential(   \n",
    "            nn.Flatten(start_dim=1, ),\n",
    "            #each Maxpool make the images into half. \n",
    "            # so after the Maxpool image size become 64 ==> 32 ==>16 ==> 8\n",
    "            nn.Linear(8*8*64, 1024), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, classes)\n",
    "        )\n",
    "\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            nn.Linear(classes, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 8*8*64),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, unflattened_size= (64, 8, 8))\n",
    "        )\n",
    "        \n",
    "        self.decoder_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "        \n",
    "        self.decoder_pool1 = nn.Sequential(\n",
    "            nn.MaxUnpool2d(2, stride=2)\n",
    "        )\n",
    "            \n",
    "        self.decoder_2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "        \n",
    "        self.decoder_pool2 = nn.Sequential(\n",
    "            nn.MaxUnpool2d(2)\n",
    "        )\n",
    "        self.decoder_3 = nn.Sequential(\n",
    "            # nn.ConvTranspose2d(16, in_features, kernel_size=3),\n",
    "            # nn.ReLU(),\n",
    "            # nn.BatchNorm2d(in_features)\n",
    "        )\n",
    "        self.decoder_pool3 = nn.Sequential(\n",
    "            nn.MaxUnpool2d(2, stride=2)\n",
    "        )\n",
    "            # # nn.AdaptiveAvgPool2d((1, 1)),\n",
    "\n",
    "\n",
    "    def forward(self, x, indices1, indices2, indices3):\n",
    "        x           = self.encoder_1(x) \n",
    "        x, indices1 = self.encoder_pool1(x)\n",
    "        x           = self.encoder_2(x)\n",
    "        x, indices2 = self.encoder_pool2(x)\n",
    "        x           = self.encoder_3(x)\n",
    "        x, indices3 = self.encoder_pool3(x)\n",
    "        x           = self.encoder_lin(x)\n",
    "        x           = self.decoder_lin(x)\n",
    "        x           = self.decoder_1(x) \n",
    "        x           = self.decoder_pool1(x, indices1)\n",
    "        x           = self.decoder_2(x)\n",
    "        x           = self.decoder_pool2(x, indices2)\n",
    "        x           = self.decoder_3(x)\n",
    "        x           = self.decoder_pool3(x, indices3)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN_AE(nn.Module):\n",
    "    def __init__(self, in_features=3, classes=50):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_features, 16, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "        \n",
    "        self.decoder_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "        self.unpool = nn.MaxUnpool2d(2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x           = self.encoder_1(x) \n",
    "        print(f' encoder: {x.size()}')\n",
    "        x, indices = self.pool(x)\n",
    "        print(f'indices: {indices.size()}')\n",
    "        indices = torch.cat((indices,indices), 1)\n",
    "        print(f'indices: {indices.size()}')\n",
    "        print(f' pool: {x.size()}')\n",
    "        x  = self.decoder_1(x)\n",
    "        print(f' decoder: {x.size()}')\n",
    "        x = self.unpool(x, indices)\n",
    "        print(f' unpool: {x.size()}')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN_AE(nn.Module):\n",
    "    def __init__(self, in_features=3, classes=50):\n",
    "        super().__init__()\n",
    "        self.encoder_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_features, 16, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "        )\n",
    "\n",
    "        self.encoder_pool1 = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "  \n",
    "            \n",
    "        self.encoder_2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            # nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "        )\n",
    "        self.encoder_pool2 = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "\n",
    "        self.encoder_lin = nn.Sequential(   \n",
    "            nn.Flatten(start_dim=1, ),\n",
    "            #each Maxpool make the images into half. \n",
    "            # so after the Maxpool image size become 64 ==> 32 ==>16 ==> 8\n",
    "            nn.Linear(16*16*32, 1024), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, classes)\n",
    "        )\n",
    "\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            nn.Linear(classes, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 16*16*32),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, unflattened_size= (32, 16, 16))\n",
    "        )\n",
    "        self.decoder_pool1 = nn.MaxUnpool2d(2, stride=2, padding=0)\n",
    "        \n",
    "        self.decoder_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "        \n",
    "        #\n",
    "            \n",
    "        self.decoder_2 = nn.Sequential(\n",
    "             nn.ConvTranspose2d(16, 16, kernel_size=3),\n",
    "             nn.LeakyReLU(),\n",
    "             nn.BatchNorm2d(16)\n",
    "         )\n",
    "        \n",
    "        # self.decoder_pool2 = nn.Sequential(\n",
    "        #     nn.MaxUnpool2d(2)\n",
    "        # )\n",
    "        # self.decoder_3 = nn.Sequential(\n",
    "        #     # nn.ConvTranspose2d(16, in_features, kernel_size=3),\n",
    "        #     # nn.ReLU(),\n",
    "        #     # nn.BatchNorm2d(in_features)\n",
    "        # )\n",
    "        # self.decoder_pool3 = nn.Sequential(\n",
    "        #     nn.MaxUnpool2d(2, stride=2)\n",
    "        # )\n",
    "            # # nn.AdaptiveAvgPool2d((1, 1)),\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x           = self.encoder_1(x) \n",
    "        x, indices1 = self.encoder_pool1(x)\n",
    "        print(f' encoder: {x.size()}')\n",
    "        print(f' indices1: {indices1.size()}')\n",
    "        indices1 = torch.cat((indices1,indices1), 1)\n",
    "        print(f' indices1: {indices1.size()}')\n",
    "        x           = self.encoder_2(x)\n",
    "        x, indices2 = self.encoder_pool2(x)\n",
    "        #indices2 = torch.cat((indices2,indices2), 1)\n",
    "        x           = self.encoder_lin(x)\n",
    "        x           = self.decoder_lin(x)\n",
    "        print(f' indices2: {indices2.size()}')\n",
    "        x           = self.decoder_pool1(x, indices2)\n",
    "        print(f' pool1: {x.size()}')\n",
    "        x           = self.decoder_1(x) \n",
    "        print(f' decoder1: {x.size()}')\n",
    "        x           = self.decoder_2(x)\n",
    "        print(f' decoder2: {x.size()}')\n",
    "        \n",
    "        # x           = self.decoder_2(x)\n",
    "        # x           = self.decoder_pool2(x, indices2)\n",
    "        # x           = self.decoder_3(x)\n",
    "        # x           = self.decoder_pool3(x, indices3)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_block(in_features, out_features, kernel_size=3, padding=1):\n",
    "            \"\"\" run 1 block of convolution  \n",
    "            \n",
    "            \"\"\"\n",
    "            block = nn.Sequential(\n",
    "                nn.Conv2d(in_features, out_features, kernel_size=3, padding=1),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.BatchNorm2d(out_features),\n",
    "                \n",
    "            )\n",
    "            # mx_pool = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "            return block\n",
    "        \n",
    "def dec_block(in_features, out_features, kernel_size=3, padding=1):\n",
    "            \"\"\" run 1 block of convolution  \n",
    "            \n",
    "            \"\"\"\n",
    "            block = nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_features, out_features, kernel_size=3, padding=1),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.BatchNorm2d(out_features),\n",
    "                \n",
    "            )\n",
    "            # mx_pool = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "            return block\n",
    "        \n",
    "def print_shape(block_type, x):\n",
    "    return print(f' {block_type} with shape: {x.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    This class represents the tail of ResNet. It performs a global pooling and maps the output to the\n",
    "    correct class by using a fully connected layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, n_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder_1 = enc_block(in_features, 16, kernel_size=3, padding=1)\n",
    "        self.encoder_pool1 = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "        \n",
    "        self.encoder_2 = enc_block(16, 32, kernel_size=3, padding=1)\n",
    "        self.encoder_pool2 = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "        \n",
    "        self.encoder_lin = nn.Sequential(   \n",
    "            nn.Flatten(start_dim=1, ),\n",
    "            #each Maxpool make the images into half. \n",
    "            # so after the Maxpool image size become 64 ==> 32 ==>16 ==> 8\n",
    "            nn.Linear(16*16*32, 1024), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_classes)\n",
    "        )\n",
    " \n",
    "\n",
    "    def forward(self, x):\n",
    "        x            = self.encoder_1(x)\n",
    "        x, indices_1 = self.encoder_pool1(x)\n",
    "        x            = self.encoder_2(x)\n",
    "        x, indices_2 = self.encoder_pool2(x)\n",
    "        x            = self.encoder_lin(x)\n",
    "        return x, indices_1, indices_2\n",
    "\n",
    "\n",
    "\n",
    "class CNN_decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    This class represents the tail of ResNet. It performs a global pooling and maps the output to the\n",
    "    correct class by using a fully connected layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            nn.Linear(n_classes, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 16*16*32),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, unflattened_size= (32, 16, 16))\n",
    "        )\n",
    "        \n",
    "        self.mx_pool_1 = nn.MaxUnpool2d(2, stride=2)\n",
    "        self.decoder_1 = dec_block(32, 16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.mx_pool_2 = nn.MaxUnpool2d(2, stride=2)\n",
    "        self.decoder_2 = dec_block(16, in_features, kernel_size=3, padding=1)\n",
    "\n",
    "\n",
    "    def forward(self, x, indices_1, indices_2):\n",
    "\n",
    "        x  = self.decoder_lin(x)\n",
    "        x  = self.mx_pool_1 (x,  indices_2)\n",
    "        x  = self.decoder_1(x)\n",
    "        x  = self.mx_pool_2 (x,  indices_1)\n",
    "        x  = self.decoder_2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "class CNN_AE(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels=3, n_classes=50, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = CNN_encoder(in_channels, n_classes = 50, *args, **kwargs)\n",
    "        self.decoder = CNN_decoder(in_channels, n_classes = 50, *args, **kwargs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, indices_1, indices_2 = self.encoder(x)\n",
    "        print_shape(\"indices_1\", indices_1)\n",
    "        print_shape(\"indices_2\", indices_2)\n",
    "        print_shape(\"x\", x)\n",
    "        x = self.decoder(x, indices_1, indices_2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_encoder(nn.Module):\n",
    "\n",
    "        \n",
    "    def __init__(self, in_features, n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder_1 = enc_block(in_features, 16, kernel_size=3, padding=1)\n",
    "        # self.mx_pool_1 = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "        \n",
    "        # self.encoder_2 = enc_block(16, 32, kernel_size=3, padding=1)\n",
    "        # self.mx_pool_2 = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "\n",
    "        \n",
    "        # self.encoder_lin = nn.Sequential(   \n",
    "        #     nn.Flatten(start_dim=1, ),\n",
    "        #     #each Maxpool make the images into half. \n",
    "        #     # so after the Maxpool image size become 64 ==> 32 ==>16 ==> 8\n",
    "        #     nn.Linear(16*16*32, 1024), \n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(1024, 128),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(128, n_classes)\n",
    "        # )\n",
    "\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x            = self.encoder_1(x) \n",
    "        print_shape(\"encoder_1\", x)\n",
    "        # x, indices_1 = self.mx_pool_1(x)\n",
    "        # x            = self.encoder_2(x)\n",
    "        # print_shape(\"encoder_2\", x)\n",
    "        # x, indices_2 = self.mx_pool_2(x)\n",
    "        # x            = self.encoder_lin(x)\n",
    "        # print_shape(\"encoder_lin\", x)\n",
    "        # # x           = self.encoder_lin(x)\n",
    "        \n",
    "        # return x, indices_1, indices_2\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CNN_decoder(nn.Module):\n",
    "\n",
    "        \n",
    "    def __init__(self, in_features=3, n_classes = 50):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.decoder_lin = nn.Sequential(\n",
    "        #     nn.Linear(n_classes, 128),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(128, 1024),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(1024, 16*16*32),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Unflatten(1, unflattened_size= (32, 16, 16))\n",
    "        # )\n",
    "        \n",
    "        # self.mx_pool_1 = nn.MaxUnpool2d(2, stride=2)\n",
    "        # self.decoder_1 = dec_block(32, 16, kernel_size=3, padding=1)\n",
    "        \n",
    "        \n",
    "        # self.decoder_2 = dec_block(16, in_features, kernel_size=3, padding=1)\n",
    "        # self.mx_pool_2 = nn.MaxUnpool2d(2, stride=2)\n",
    "  \n",
    "    def forward(self, x, indices_1):\n",
    "        \n",
    "        # x = self.decoder_lin(x)\n",
    "        # print_shape(\"decoder_lin\", x)\n",
    "        # x = self.mx_pool_1(x, indices_1)\n",
    "        # print_shape(\"decoder_p1\", x)\n",
    "        # x = self.decoder_1(x) \n",
    "        # print_shape(\"decoder_2\", x)\n",
    "        # x = self.decoder_2(x)\n",
    "        # x = self.mx_pool_2(x, indices_2)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CNN_AE(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features=3, n_classes = 50, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = CNN_encoder(in_features, n_classes)\n",
    "        # self.decoder = CNN_decoder(in_features, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        # print(len(indices_1[1]))\n",
    "        # print(len(indices_2[1]))\n",
    "        #x= self.decoder(x, indices_1)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda acceleration enabled!\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchsummary import summary\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Cuda acceleration enabled!\" if torch.cuda.is_available() else 'Running on CPU')\n",
    "\n",
    "\n",
    "def get_model(model_saved_path=None):\n",
    "    # initializing model\n",
    "    model = CNN_AE()\n",
    "    if model_saved_path:\n",
    "        print(\"loading Model from saved weight\")\n",
    "        model.load_state_dict(torch.load(model_saved_path))\n",
    "        model.eval()\n",
    "        print(summary(model, (3, 64, 64)))\n",
    "    else:\n",
    "        model.eval()\n",
    "        print(summary(model, (3, 64, 64)))\n",
    "        print(\"Building Model from scratch\")\n",
    "    \n",
    "    # using gpu\n",
    "    model = model.cuda() if torch.cuda.is_available() else model\n",
    "    # print(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation(model, train_dataloader, loss_fn):\n",
    "    losses = []\n",
    "    model.eval()\n",
    "    for image, target, _ in train_dataloader:\n",
    "        image, target = image.to(DEVICE), target.to(DEVICE)\n",
    "        output = model(image)\n",
    "        loss = loss_fn(output, target)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    return np.array(losses).mean()\n",
    "\n",
    "\n",
    "def loss_fn(y_pred, y_true):\n",
    "    bce_fn = nn.CrossEntropyLoss()\n",
    "    loss = bce_fn(y_pred, y_true)\n",
    "    return loss\n",
    "\n",
    "\n",
    "### Table for results\n",
    "header = r'''\n",
    "        Train | Valid\n",
    "Epoch |  Loss |  Loss | Time, m | Save status\n",
    "'''\n",
    "#          Epoch         metrics            time\n",
    "raw_line = '{:6d}' + '\\u2502{:7.3f}'*2 + '\\u2502{:6.2f}' + '\\t' + '\\u2502 {}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " indices_1 with shape: torch.Size([2, 16, 32, 32])\n",
      " indices_2 with shape: torch.Size([2, 32, 16, 16])\n",
      " x with shape: torch.Size([2, 50])\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─CNN_encoder: 1-1                       [-1, 50]                  --\n",
      "|    └─Sequential: 2-1                   [-1, 16, 64, 64]          --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 16, 64, 64]          448\n",
      "|    |    └─LeakyReLU: 3-2               [-1, 16, 64, 64]          --\n",
      "|    |    └─BatchNorm2d: 3-3             [-1, 16, 64, 64]          32\n",
      "|    └─MaxPool2d: 2-2                    [-1, 16, 32, 32]          --\n",
      "|    └─Sequential: 2-3                   [-1, 32, 32, 32]          --\n",
      "|    |    └─Conv2d: 3-4                  [-1, 32, 32, 32]          4,640\n",
      "|    |    └─LeakyReLU: 3-5               [-1, 32, 32, 32]          --\n",
      "|    |    └─BatchNorm2d: 3-6             [-1, 32, 32, 32]          64\n",
      "|    └─MaxPool2d: 2-4                    [-1, 32, 16, 16]          --\n",
      "|    └─Sequential: 2-5                   [-1, 50]                  --\n",
      "|    |    └─Flatten: 3-7                 [-1, 8192]                --\n",
      "|    |    └─Linear: 3-8                  [-1, 1024]                8,389,632\n",
      "|    |    └─ReLU: 3-9                    [-1, 1024]                --\n",
      "|    |    └─Linear: 3-10                 [-1, 128]                 131,200\n",
      "|    |    └─ReLU: 3-11                   [-1, 128]                 --\n",
      "|    |    └─Linear: 3-12                 [-1, 50]                  6,450\n",
      "├─CNN_decoder: 1-2                       [-1, 3, 64, 64]           --\n",
      "|    └─Sequential: 2-6                   [-1, 32, 16, 16]          --\n",
      "|    |    └─Linear: 3-13                 [-1, 128]                 6,528\n",
      "|    |    └─ReLU: 3-14                   [-1, 128]                 --\n",
      "|    |    └─Linear: 3-15                 [-1, 1024]                132,096\n",
      "|    |    └─ReLU: 3-16                   [-1, 1024]                --\n",
      "|    |    └─Linear: 3-17                 [-1, 8192]                8,396,800\n",
      "|    |    └─ReLU: 3-18                   [-1, 8192]                --\n",
      "|    |    └─Unflatten: 3-19              [-1, 32, 16, 16]          --\n",
      "|    └─MaxUnpool2d: 2-7                  [-1, 32, 32, 32]          --\n",
      "|    └─Sequential: 2-8                   [-1, 16, 32, 32]          --\n",
      "|    |    └─ConvTranspose2d: 3-20        [-1, 16, 32, 32]          4,624\n",
      "|    |    └─LeakyReLU: 3-21              [-1, 16, 32, 32]          --\n",
      "|    |    └─BatchNorm2d: 3-22            [-1, 16, 32, 32]          32\n",
      "|    └─MaxUnpool2d: 2-9                  [-1, 16, 64, 64]          --\n",
      "|    └─Sequential: 2-10                  [-1, 3, 64, 64]           --\n",
      "|    |    └─ConvTranspose2d: 3-23        [-1, 3, 64, 64]           435\n",
      "|    |    └─LeakyReLU: 3-24              [-1, 3, 64, 64]           --\n",
      "|    |    └─BatchNorm2d: 3-25            [-1, 3, 64, 64]           6\n",
      "==========================================================================================\n",
      "Total params: 17,072,987\n",
      "Trainable params: 17,072,987\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 64.15\n",
      "==========================================================================================\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 2.02\n",
      "Params size (MB): 65.13\n",
      "Estimated Total Size (MB): 67.19\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─CNN_encoder: 1-1                       [-1, 50]                  --\n",
      "|    └─Sequential: 2-1                   [-1, 16, 64, 64]          --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 16, 64, 64]          448\n",
      "|    |    └─LeakyReLU: 3-2               [-1, 16, 64, 64]          --\n",
      "|    |    └─BatchNorm2d: 3-3             [-1, 16, 64, 64]          32\n",
      "|    └─MaxPool2d: 2-2                    [-1, 16, 32, 32]          --\n",
      "|    └─Sequential: 2-3                   [-1, 32, 32, 32]          --\n",
      "|    |    └─Conv2d: 3-4                  [-1, 32, 32, 32]          4,640\n",
      "|    |    └─LeakyReLU: 3-5               [-1, 32, 32, 32]          --\n",
      "|    |    └─BatchNorm2d: 3-6             [-1, 32, 32, 32]          64\n",
      "|    └─MaxPool2d: 2-4                    [-1, 32, 16, 16]          --\n",
      "|    └─Sequential: 2-5                   [-1, 50]                  --\n",
      "|    |    └─Flatten: 3-7                 [-1, 8192]                --\n",
      "|    |    └─Linear: 3-8                  [-1, 1024]                8,389,632\n",
      "|    |    └─ReLU: 3-9                    [-1, 1024]                --\n",
      "|    |    └─Linear: 3-10                 [-1, 128]                 131,200\n",
      "|    |    └─ReLU: 3-11                   [-1, 128]                 --\n",
      "|    |    └─Linear: 3-12                 [-1, 50]                  6,450\n",
      "├─CNN_decoder: 1-2                       [-1, 3, 64, 64]           --\n",
      "|    └─Sequential: 2-6                   [-1, 32, 16, 16]          --\n",
      "|    |    └─Linear: 3-13                 [-1, 128]                 6,528\n",
      "|    |    └─ReLU: 3-14                   [-1, 128]                 --\n",
      "|    |    └─Linear: 3-15                 [-1, 1024]                132,096\n",
      "|    |    └─ReLU: 3-16                   [-1, 1024]                --\n",
      "|    |    └─Linear: 3-17                 [-1, 8192]                8,396,800\n",
      "|    |    └─ReLU: 3-18                   [-1, 8192]                --\n",
      "|    |    └─Unflatten: 3-19              [-1, 32, 16, 16]          --\n",
      "|    └─MaxUnpool2d: 2-7                  [-1, 32, 32, 32]          --\n",
      "|    └─Sequential: 2-8                   [-1, 16, 32, 32]          --\n",
      "|    |    └─ConvTranspose2d: 3-20        [-1, 16, 32, 32]          4,624\n",
      "|    |    └─LeakyReLU: 3-21              [-1, 16, 32, 32]          --\n",
      "|    |    └─BatchNorm2d: 3-22            [-1, 16, 32, 32]          32\n",
      "|    └─MaxUnpool2d: 2-9                  [-1, 16, 64, 64]          --\n",
      "|    └─Sequential: 2-10                  [-1, 3, 64, 64]           --\n",
      "|    |    └─ConvTranspose2d: 3-23        [-1, 3, 64, 64]           435\n",
      "|    |    └─LeakyReLU: 3-24              [-1, 3, 64, 64]           --\n",
      "|    |    └─BatchNorm2d: 3-25            [-1, 3, 64, 64]           6\n",
      "==========================================================================================\n",
      "Total params: 17,072,987\n",
      "Trainable params: 17,072,987\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 64.15\n",
      "==========================================================================================\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 2.02\n",
      "Params size (MB): 65.13\n",
      "Estimated Total Size (MB): 67.19\n",
      "==========================================================================================\n",
      "Building Model from scratch\n"
     ]
    }
   ],
   "source": [
    "# loading the model\n",
    "\n",
    "trained_model_PATH = trained_weights +'TBCells.pt'\n",
    "model = get_model()\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "# # not optimizing the whole network for now\n",
    "# # optimizer = torch.optim.AdamW(model.parameters(),\n",
    "# #                   lr=1e-4, weight_decay=1e-3)\n",
    "\n",
    "# ignored_params = list(map(id, model.fc.parameters()))\n",
    "# base_params = filter(lambda p: id(p) not in ignored_params,\n",
    "#                      model.parameters())\n",
    "\n",
    "learning_rate = 4e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting validation vs train error\n",
    "\n",
    "def loss_plot(batch_losses,vlosses):\n",
    "    fig, ax = plt.subplots(1, 1, figsize = (9, 5))\n",
    "\n",
    "    plt.title(\"Train-Validation Accuracy\")\n",
    "    plt.plot(batch_losses, label='train')\n",
    "    plt.plot(vlosses, label='validation')\n",
    "    plt.xlabel('num_epochs', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    ax.legend(loc='best')\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(trained_weights + \"Train_Validation_Accuracy.png\", bbox_inches='tight', dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHES = 350\n",
    "vloss_min = np.Inf\n",
    "print(header)\n",
    "batch_losses = []\n",
    "vlosses = []\n",
    "\n",
    "for epoch in range(1, EPOCHES+1):\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    for image, target, _ in train_dataloader:\n",
    "        image, target = image.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    vloss = validation(model, test_dataloader, loss_fn)\n",
    "    \n",
    "    batch_loss = np.array(losses).mean()\n",
    "    batch_losses.append(batch_loss)\n",
    "    \n",
    "    vlosses.append(vloss)\n",
    "    if vloss_min > vloss:\n",
    "        vloss_min = vloss\n",
    "        torch.save(model.state_dict(), trained_weights +'TBCells.pt')\n",
    "        save_status = 'Yes'\n",
    "        loss_plot(batch_losses,vlosses)\n",
    "    else:\n",
    "        save_status = 'No'\n",
    "        \n",
    "    print(raw_line.format(epoch, batch_loss, vloss,\n",
    "                              (time.time()-start_time)/60**1, save_status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruct model from saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restart = False\n",
    "if restart:\n",
    "    model1 = torchvision.models.resnet50()\n",
    "    model1.fc = torch.nn.Sequential(\n",
    "        torch.nn.Linear(\n",
    "            in_features=2048,\n",
    "            out_features=1\n",
    "        ),\n",
    "        torch.nn.Sigmoid()\n",
    "    )\n",
    "    model1.load_state_dict(torch.load(trained_weights +'TBCells.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# validating dataset\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# defining hook to access output from intermidiate layer\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# registerning the hook. different layer can be accessed by changing\n",
    "# fc[3] parameter. for details \n",
    "# https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2021/05/27/extracting-features.html\n",
    "\n",
    "# print(model)\n",
    "model.decoder[0].register_forward_hook(get_features('feats'))\n",
    "\n",
    "\n",
    "trained_model_PATH = trained_weights +'TBCells.pt'\n",
    "model.load_state_dict(torch.load(trained_model_PATH))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "FEATS = [] # extracted feats will be saved here\n",
    "# placeholder for batch features\n",
    "features = {}\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image, target, path in test_dataloader:\n",
    "        image, target = image.to(DEVICE), target.to(DEVICE)\n",
    "        outputs = model(image)\n",
    "        output = (torch.max(outputs, 1)[1]).data.cpu().numpy()\n",
    "        y_pred.extend(output) # Save Prediction\n",
    "        target = target.data.cpu().numpy()\n",
    "        \n",
    "        # not_matched = [target.index(y) for x, y in zip(y_pred, target) if y != x]\n",
    "        not_matched = np.where(y_pred != target)[0]\n",
    "        if not os.path.exists(trained_weights + \"wrong_pred/\"):\n",
    "            os.makedirs(trained_weights + \"wrong_pred/\")\n",
    "            for element in not_matched:\n",
    "                shutil.copy(path[element], trained_weights + \"wrong_pred/\" + path[element].split(\"/\")[-1]) \n",
    "        y_true.extend(target) # Save Truth\n",
    "        FEATS.extend((features['feats'].cpu().numpy())) # Save feature\n",
    "       \n",
    "print(f' Feature extracted with shape: {np.array(FEATS).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = labels_map.values()   \n",
    " \n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "class_accuracy=np.mean(100*cf_matrix.diagonal()/cf_matrix.sum(1))\n",
    "print(f'average acuraccy of all classes: {class_accuracy}')\n",
    "\n",
    "# ploting \n",
    "font = {'family' : 'Arial',\n",
    "        'size'   : 20}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "fig, ax = plt.subplots( dpi = 150)\n",
    "sn.heatmap(cf_matrix, annot=True, cmap='Blues',fmt='g')\n",
    "ax.set_title(f'Confusion Matrix, average acuracy: {class_accuracy :.2f}', fontsize = 15)\n",
    "ax.xaxis.set_ticklabels(classes); ax.yaxis.set_ticklabels(classes);\n",
    "plt.xlabel('Predicted'); plt.ylabel('True');\n",
    "\n",
    "plt.savefig(trained_weights + 'cf_matrix.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "cls_report = classification_report(y_true, y_pred, target_names=classes, output_dict=True)\n",
    "df = pd.DataFrame(cls_report)\n",
    "# df.drop(columns=['accuracy'])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (9, 5))\n",
    "\n",
    "sns.heatmap(df.iloc[:-1, :].T, annot=True)\n",
    "fig.tight_layout()\n",
    "plt.savefig(trained_weights + \"classification_report.png\", bbox_inches='tight', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(FEATS).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-SNE plot\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import cm\n",
    "\n",
    "# Create a two dimensional t-SNE projection of the embeddings\n",
    "tsne = TSNE(2, verbose=0, perplexity=50, n_iter=5000)\n",
    "tsne_proj = tsne.fit_transform(FEATS)\n",
    "# Plot those points as a scatter plot and label them based on the pred labels\n",
    "\n",
    "cmap = cm.get_cmap('tab20')\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "for lab in range(len(labels_map)):\n",
    "    indices = np.array(y_pred)==lab\n",
    "    #ax.scatter(tsne_proj[indices,0],tsne_proj[indices,1], c=np.array(cmap(lab)).reshape(1,4), label = lab ,alpha=0.5)\n",
    "    ax.scatter(tsne_proj[indices,0],tsne_proj[indices,1], label = lab ,alpha=0.5)\n",
    "ax.legend(fontsize='large', markerscale=2)\n",
    "plt.savefig(trained_weights + \"T-SNE.png\", bbox_inches='tight', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install keyboard\n",
    "#import keyboard\n",
    "#keyboard.press_and_release('command+s')\n",
    "\n",
    "nb_name = \"test.ipynb\"\n",
    "nb_full_path = os.path.join(os.getcwd(), nb_name)\n",
    "\n",
    "import shutil\n",
    "shutil.copyfile(nb_full_path, trained_weights  + nb_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52935d2f357a1e9b1e82836401a8d9e7860cec2909db9f1bc85e95f9b8c17282"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
